{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "df = pd.read_csv('sample.csv')\n",
    "std_scale = StandardScaler().fit(df)\n",
    "df_std = pd.DataFrame(std_scale.transform(df), columns=df.columns)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# df = pd.read_csv('vars_308.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "with open('ks_stat.csv', 'r') as f:\n",
    "    lines = f.read().split('\\n')\n",
    "    ks_stat = [i.split(',') for i in lines]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "y = df['fraud_label'].to_numpy()\n",
    "df_std.drop(columns=['record', 'fraud_label'], inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "ks_col = [i[0] for i in ks_stat[:102]]\n",
    "ks_df = df_std.filter(items=ks_col)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [],
   "source": [
    "def fdr(y, cutoff=0.03, *, prob=None, classifier=None, x=None):\n",
    "    if prob is None:\n",
    "        assert classifier is not None\n",
    "        prob = classifier.predict_proba(x)\n",
    "    if len(prob.shape) == 2:\n",
    "        prob = prob[:, -1:]\n",
    "    fraud_num = len(y[y == 1])\n",
    "    total_num = len(y)\n",
    "    fraud_prob = [(i, j) for i, j in zip(prob, y)]\n",
    "    sorted_prob = sorted(fraud_prob, key=lambda x: x[0], reverse=True)\n",
    "    cutoff_bin = sorted_prob[0:int(total_num * cutoff)]\n",
    "    return len(cutoff_bin[cutoff_bin == 1]) / fraud_num"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# forward selection\n",
    "best_feature = set()\n",
    "while len(best_feature) < 30:\n",
    "    # get candidate variables\n",
    "    candidate = set(ks_df.columns) - best_feature\n",
    "    \n",
    "    # calculate FDR\n",
    "    scores = dict()\n",
    "    for col in candidate:\n",
    "        features = list(best_feature) + [col]\n",
    "        test_x = ks_df.filter(items=features)\n",
    "        if len(features) == 1:\n",
    "            # only one feature, reshape needed\n",
    "            test_x = test_x.to_numpy().reshape(-1, 1)\n",
    "        sample_x, sample_y = RandomUnderSampler().fit_resample(test_x, y)\n",
    "        classifier = LogisticRegression().fit(sample_x, sample_y)\n",
    "        scores[col] = fdr(classifier, test_x, y)\n",
    "    \n",
    "    # get the best feature\n",
    "    best = max(scores.items(), key=operator.itemgetter(1))\n",
    "    best_feature.add(best[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [],
   "source": [
    "y = df['fraud_label'].to_numpy()\n",
    "x = ks_df.iloc[:, 2:5].to_numpy()\n",
    "# a = a.to_numpy().reshape(-1, 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "x_f = [i for i, j in zip(x, y) if j == 1]\n",
    "x_nf = [i for i, j in zip(x, y) if j == 0]\n",
    "x_sample = random.sample(x_nf, len(x_f)) + x_f\n",
    "y_sample = [0] * len(x_f) + [1] * len(x_f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "x_sample, y_sample = sklearn.utils.shuffle(x_sample, y_sample)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "0.021052631578947368"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression().fit(x_sample, y_sample)\n",
    "fdr(clf, x_sample, np.asarray(y_sample))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.53309798, 0.46690202],\n       [0.53309798, 0.46690202],\n       [0.57298533, 0.42701467],\n       [0.45256159, 0.54743841],\n       [0.53309798, 0.46690202],\n       [0.53309798, 0.46690202],\n       [0.45256159, 0.54743841],\n       [0.53309798, 0.46690202],\n       [0.53309798, 0.46690202],\n       [0.08810725, 0.91189275],\n       [0.45256159, 0.54743841],\n       [0.45256159, 0.54743841],\n       [0.57298533, 0.42701467],\n       [0.45256159, 0.54743841],\n       [0.53309798, 0.46690202],\n       [0.57298533, 0.42701467],\n       [0.49278296, 0.50721704],\n       [0.57298533, 0.42701467],\n       [0.57298533, 0.42701467],\n       [0.49278296, 0.50721704],\n       [0.10197121, 0.89802879],\n       [0.57298533, 0.42701467],\n       [0.57298533, 0.42701467],\n       [0.57298533, 0.42701467],\n       [0.57298533, 0.42701467],\n       [0.45256159, 0.54743841],\n       [0.49278296, 0.50721704],\n       [0.57298533, 0.42701467],\n       [0.57298533, 0.42701467],\n       [0.57298533, 0.42701467],\n       [0.10197121, 0.89802879],\n       [0.53309798, 0.46690202],\n       [0.57298533, 0.42701467],\n       [0.53309798, 0.46690202],\n       [0.53309798, 0.46690202],\n       [0.49278296, 0.50721704],\n       [0.49278296, 0.50721704],\n       [0.49278296, 0.50721704],\n       [0.49278296, 0.50721704],\n       [0.57298533, 0.42701467],\n       [0.45256159, 0.54743841],\n       [0.49278296, 0.50721704],\n       [0.03197547, 0.96802453],\n       [0.53309798, 0.46690202],\n       [0.57298533, 0.42701467],\n       [0.49278296, 0.50721704],\n       [0.57298533, 0.42701467],\n       [0.53309798, 0.46690202],\n       [0.53309798, 0.46690202],\n       [0.53309798, 0.46690202],\n       [0.53309798, 0.46690202],\n       [0.03197547, 0.96802453],\n       [0.53309798, 0.46690202],\n       [0.53309798, 0.46690202],\n       [0.53309798, 0.46690202],\n       [0.49278296, 0.50721704],\n       [0.57298533, 0.42701467],\n       [0.53309798, 0.46690202],\n       [0.57298533, 0.42701467],\n       [0.53309798, 0.46690202],\n       [0.53309798, 0.46690202],\n       [0.57298533, 0.42701467],\n       [0.57298533, 0.42701467],\n       [0.49278296, 0.50721704],\n       [0.57298533, 0.42701467],\n       [0.53309798, 0.46690202],\n       [0.49278296, 0.50721704],\n       [0.57298533, 0.42701467],\n       [0.45256159, 0.54743841],\n       [0.49278296, 0.50721704],\n       [0.49278296, 0.50721704],\n       [0.49278296, 0.50721704],\n       [0.53309798, 0.46690202],\n       [0.57298533, 0.42701467],\n       [0.57298533, 0.42701467],\n       [0.57298533, 0.42701467],\n       [0.49278296, 0.50721704],\n       [0.57298533, 0.42701467],\n       [0.53309798, 0.46690202],\n       [0.53309798, 0.46690202],\n       [0.53309798, 0.46690202],\n       [0.57298533, 0.42701467],\n       [0.45256159, 0.54743841],\n       [0.49278296, 0.50721704],\n       [0.45256159, 0.54743841],\n       [0.57298533, 0.42701467],\n       [0.53309798, 0.46690202],\n       [0.57298533, 0.42701467],\n       [0.57298533, 0.42701467],\n       [0.45256159, 0.54743841],\n       [0.53309798, 0.46690202],\n       [0.49278296, 0.50721704],\n       [0.53309798, 0.46690202],\n       [0.53309798, 0.46690202],\n       [0.53309798, 0.46690202],\n       [0.49278296, 0.50721704],\n       [0.49278296, 0.50721704],\n       [0.45256159, 0.54743841],\n       [0.45256159, 0.54743841],\n       [0.49278296, 0.50721704],\n       [0.57298533, 0.42701467],\n       [0.53309798, 0.46690202],\n       [0.49278296, 0.50721704],\n       [0.08810725, 0.91189275],\n       [0.49278296, 0.50721704],\n       [0.45256159, 0.54743841],\n       [0.49278296, 0.50721704],\n       [0.57298533, 0.42701467],\n       [0.53309798, 0.46690202],\n       [0.45256159, 0.54743841],\n       [0.53309798, 0.46690202],\n       [0.53309798, 0.46690202],\n       [0.53309798, 0.46690202],\n       [0.57298533, 0.42701467],\n       [0.57298533, 0.42701467],\n       [0.45256159, 0.54743841],\n       [0.49278296, 0.50721704],\n       [0.49278296, 0.50721704],\n       [0.10197121, 0.89802879],\n       [0.57298533, 0.42701467],\n       [0.45256159, 0.54743841],\n       [0.49278296, 0.50721704],\n       [0.53309798, 0.46690202],\n       [0.45256159, 0.54743841],\n       [0.53309798, 0.46690202],\n       [0.57298533, 0.42701467],\n       [0.57298533, 0.42701467],\n       [0.53309798, 0.46690202],\n       [0.49278296, 0.50721704],\n       [0.53309798, 0.46690202],\n       [0.49278296, 0.50721704],\n       [0.49278296, 0.50721704],\n       [0.53309798, 0.46690202],\n       [0.53309798, 0.46690202],\n       [0.53309798, 0.46690202],\n       [0.45256159, 0.54743841],\n       [0.53309798, 0.46690202],\n       [0.53309798, 0.46690202],\n       [0.57298533, 0.42701467],\n       [0.49278296, 0.50721704],\n       [0.10197121, 0.89802879],\n       [0.53309798, 0.46690202],\n       [0.49278296, 0.50721704],\n       [0.57298533, 0.42701467],\n       [0.53309798, 0.46690202],\n       [0.45256159, 0.54743841],\n       [0.53309798, 0.46690202],\n       [0.45256159, 0.54743841],\n       [0.49278296, 0.50721704],\n       [0.57298533, 0.42701467],\n       [0.53309798, 0.46690202],\n       [0.53309798, 0.46690202],\n       [0.49278296, 0.50721704],\n       [0.57298533, 0.42701467],\n       [0.45256159, 0.54743841],\n       [0.53309798, 0.46690202],\n       [0.57298533, 0.42701467],\n       [0.53309798, 0.46690202],\n       [0.57298533, 0.42701467],\n       [0.57298533, 0.42701467],\n       [0.57298533, 0.42701467],\n       [0.53309798, 0.46690202],\n       [0.49278296, 0.50721704],\n       [0.57298533, 0.42701467],\n       [0.53309798, 0.46690202],\n       [0.08810725, 0.91189275],\n       [0.57298533, 0.42701467],\n       [0.45256159, 0.54743841],\n       [0.45256159, 0.54743841],\n       [0.49278296, 0.50721704],\n       [0.53309798, 0.46690202],\n       [0.10197121, 0.89802879],\n       [0.57298533, 0.42701467],\n       [0.53309798, 0.46690202],\n       [0.49278296, 0.50721704],\n       [0.53309798, 0.46690202],\n       [0.49278296, 0.50721704],\n       [0.53309798, 0.46690202],\n       [0.49278296, 0.50721704],\n       [0.57298533, 0.42701467],\n       [0.53309798, 0.46690202],\n       [0.57298533, 0.42701467],\n       [0.24932962, 0.75067038],\n       [0.57298533, 0.42701467],\n       [0.53309798, 0.46690202],\n       [0.53309798, 0.46690202],\n       [0.45256159, 0.54743841],\n       [0.57298533, 0.42701467],\n       [0.57298533, 0.42701467],\n       [0.49278296, 0.50721704]])"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(x_sample)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5259172666648955\n",
      "0.3368421052631579\n"
     ]
    }
   ],
   "source": [
    "x_sample, y_sample = RandomUnderSampler().fit_resample(x, y)\n",
    "clf = LogisticRegression().fit(x_sample, y_sample)\n",
    "y_pre = clf.predict(x)\n",
    "print(balanced_accuracy_score(y, y_pre))\n",
    "print(recall_score(y, y_pre))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5577937777305454\n",
      "0.11578947368421053\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(class_weight='balanced').fit(x, y)\n",
    "y_pre = clf.predict(x)\n",
    "print(balanced_accuracy_score(y, y_pre))\n",
    "print(recall_score(y, y_pre))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5532479608916284\n",
      "0.2736842105263158\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "x_sample, y_sample = RandomUnderSampler().fit_resample(x, y)\n",
    "clf = RandomForestClassifier(class_weight='balanced').fit(x_sample, y_sample)\n",
    "y_pre = clf.predict(x)\n",
    "print(balanced_accuracy_score(y, y_pre))\n",
    "print(recall_score(y, y_pre))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5859294880310317\n",
      "0.6105263157894737\n"
     ]
    }
   ],
   "source": [
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "clf = BalancedBaggingClassifier().fit(x, y)\n",
    "y_pre = clf.predict(x)\n",
    "print(balanced_accuracy_score(y, y_pre))\n",
    "print(recall_score(y, y_pre))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.6505566035229416\n",
      "0.6210526315789474\n",
      "1\n",
      "0.6530061903876299\n",
      "0.6421052631578947\n",
      "2\n",
      "0.6362708892372273\n",
      "0.42105263157894735\n",
      "3\n",
      "0.6322830043306145\n",
      "0.42105263157894735\n",
      "4\n",
      "0.6671803182868833\n",
      "0.6736842105263158\n",
      "5\n",
      "0.6372671962591993\n",
      "0.4105263157894737\n",
      "6\n",
      "0.6375594463189777\n",
      "0.4421052631578947\n",
      "7\n",
      "0.6188527856744335\n",
      "0.37894736842105264\n",
      "8\n",
      "0.632431786179229\n",
      "0.37894736842105264\n",
      "9\n",
      "0.6388187783947501\n",
      "0.4\n",
      "fdr 0.021052631578947368\n"
     ]
    }
   ],
   "source": [
    "x = ks_df.to_numpy()\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "y_pre = np.zeros((len(y), 2))\n",
    "for _ in range(10):\n",
    "    x_sample, y_sample = RandomUnderSampler().fit_resample(x, y)\n",
    "    clf = LogisticRegression().fit(x_sample, y_sample)\n",
    "    y_ = clf.predict(x)\n",
    "    print(_)\n",
    "    print(balanced_accuracy_score(y, y_))\n",
    "    print(recall_score(y, y_))\n",
    "    y_pre += clf.predict_proba(x)\n",
    "y_pre /= 10\n",
    "\n",
    "print('fdr', fdr(y, prob=y_pre))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.5577937777305454\n",
      "0.11578947368421053\n",
      "1\n",
      "0.5577937777305454\n",
      "0.11578947368421053\n",
      "2\n",
      "0.5577937777305454\n",
      "0.11578947368421053\n",
      "3\n",
      "0.5577937777305454\n",
      "0.11578947368421053\n",
      "4\n",
      "0.5577937777305454\n",
      "0.11578947368421053\n",
      "5\n",
      "0.5577937777305454\n",
      "0.11578947368421053\n",
      "6\n",
      "0.5577937777305454\n",
      "0.11578947368421053\n",
      "7\n",
      "0.5577937777305454\n",
      "0.11578947368421053\n",
      "8\n",
      "0.5577937777305454\n",
      "0.11578947368421053\n",
      "9\n",
      "0.5577937777305454\n",
      "0.11578947368421053\n",
      "fdr 0.021052631578947368\n"
     ]
    }
   ],
   "source": [
    "y_pre = np.zeros((len(y), 2))\n",
    "for _ in range(10):\n",
    "    x_sample, y_sample = SMOTE(sampling_strategy=0.1).fit_resample(x, y)\n",
    "    x_sample, y_sample = RandomUnderSampler().fit_resample(x_sample, y_sample)\n",
    "    clf = LogisticRegression().fit(x_sample, y_sample)\n",
    "    y_ = clf.predict(x)\n",
    "    print(_)\n",
    "    print(balanced_accuracy_score(y, y_))\n",
    "    print(recall_score(y, y_))\n",
    "    y_pre += clf.predict_proba(x)\n",
    "y_pre /= 10\n",
    "\n",
    "print('fdr', fdr(y, prob=y_pre))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}